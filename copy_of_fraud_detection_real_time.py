# -*- coding: utf-8 -*-
"""Copy of Fraud Detection Real time.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/191Zv2eChPE_YYPWUNUfi6xfKSTD_zBT_
"""

!pip install tensorflow numpy pandas scikit-learn matplotlib

import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from sklearn.preprocessing import MinMaxScaler
import matplotlib.pyplot as plt

# Set random seed for reproducibility
np.random.seed(42)

# Number of transactions
num_samples = 5000  # 5000 fake transactions

# Generate random transaction amounts ($10 - $5000)
transaction_amounts = np.random.uniform(10, 5000, num_samples)

# Generate random transaction types (Online, In-store, Subscription, Crypto)
transaction_types = np.random.choice(['Online', 'In-store', 'Subscription', 'Crypto'], num_samples)

# Generate random device IDs (random device numbers between 1000 and 5000)
device_ids = np.random.randint(1000, 5000, num_samples)

# Generate fraud labels (5% fraud, 95% genuine)
fraud_labels = np.random.choice([0, 1], num_samples, p=[0.95, 0.05])

# Create a Pandas DataFrame
df = pd.DataFrame({
    'Transaction_Amount': transaction_amounts,
    'Transaction_Type': transaction_types,
    'Device_ID': device_ids,
    'Is_Fraud': fraud_labels
})

# Show first 5 transactions
print(df.head())

from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()
df['Transaction_Amount_Scaled'] = scaler.fit_transform(df[['Transaction_Amount']])

df['Transaction_Type_Label'] = df['Transaction_Type'].astype('category').cat.codes

time_steps = 5  # Looking at the last 5 transactions

def create_sequences(data, labels, time_steps):
    sequences = []
    seq_labels = []
    for i in range(len(data) - time_steps):
        seq = data[i:i+time_steps].values  # Select transaction features
        label = labels.iloc[i + time_steps]  # Select fraud label from original dataset
        sequences.append(seq)
        seq_labels.append(label)
    return np.array(sequences), np.array(seq_labels)

# Selecting relevant features
features = ['Transaction_Amount_Scaled', 'Transaction_Type_Label', 'Device_ID']

# Create sequences
sequences, labels = create_sequences(df[features], df['Is_Fraud'], time_steps)

# Split into Training & Testing (80% Train, 20% Test)
X_train, y_train = sequences[:4000], labels[:4000]
X_test, y_test = sequences[4000:], labels[4000:]

print(f"Training samples: {X_train.shape}, Test samples: {X_test.shape}")

# Define LSTM model
model = Sequential([
    LSTM(64, return_sequences=True, input_shape=(time_steps, len(features))),
    Dropout(0.2),  # Prevents overfitting
    LSTM(32, return_sequences=False),
    Dropout(0.2),
    Dense(16, activation='relu'),
    Dense(1, activation='sigmoid')  # Sigmoid for binary classification
])

# Compile the Model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the Model
history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))

# Evaluate Model on Test Data
loss, accuracy = model.evaluate(X_test, y_test)
print(f"Test Accuracy: {accuracy * 100:.2f}%")

# Generate a new test dataset
num_samples_test = 1000

# Generate random transaction amounts ($10 - $5000)
transaction_amounts_test = np.random.uniform(10, 5000, num_samples_test)

# Generate new transaction types (Online, In-store, Subscription, Crypto)
transaction_types_test = np.random.choice(['Online', 'In-store', 'Subscription', 'Crypto'], num_samples_test)

# Generate new device IDs
device_ids_test = np.random.randint(1000, 5000, num_samples_test)

# Generate new fraud labels (5% fraud)
fraud_labels_test = np.random.choice([0, 1], num_samples_test, p=[0.95, 0.05])

# Create a new test DataFrame
df_test = pd.DataFrame({
    'Transaction_Amount': transaction_amounts_test,
    'Transaction_Type': transaction_types_test,
    'Device_ID': device_ids_test,
    'Is_Fraud': fraud_labels_test
})

# Normalize transaction amounts using the same scaler
df_test['Transaction_Amount_Scaled'] = scaler.transform(df_test[['Transaction_Amount']])

# Convert transaction types to numerical labels
df_test['Transaction_Type_Label'] = df_test['Transaction_Type'].astype('category').cat.codes

# Prepare sequences for the new test set
X_test_new, y_test_new = create_sequences(df_test[features], df_test['Is_Fraud'], time_steps)

print(f"New Test Data Shape: {X_test_new.shape}")

# Evaluate AI model on the completely new dataset
new_loss, new_accuracy = model.evaluate(X_test_new, y_test_new)
print(f"New Unseen Test Set Accuracy: {new_accuracy * 100:.2f}% | Loss: {new_loss:.4f}")

# Plot Training & Validation Accuracy
plt.figure(figsize=(10, 5))
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.title('Model Accuracy Over Epochs')
plt.show()

# Plot Training & Validation Loss
plt.figure(figsize=(10, 5))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.title('Model Loss Over Epochs')
plt.show()